{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "18852e9e-cba6-4036-b8ae-60cefe92d5ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 Loss 0.3611\n",
      "Epoch 10 Loss 0.1752\n",
      "Epoch 20 Loss 0.0342\n",
      "Epoch 30 Loss 0.0341\n",
      "Epoch 40 Loss 0.0255\n",
      "\n",
      "LSTM RESULTS\n",
      "MAE: 0.16088875\n",
      "RMSE: 0.16735767\n",
      "MAPE: 21.74641042947769\n",
      "Walk Forward LSTM: 0.18438159\n",
      "\n",
      "XGBOOST RESULTS\n",
      "MAE: 0.029392872119595133\n",
      "RMSE: 0.03673968616608929\n",
      "MAPE: 4.043549682704524\n",
      "Walk Forward XGB: 0.03210134447350414\n",
      "\n",
      "FINAL COMPARISON COMPLETE\n"
     ]
    }
   ],
   "source": [
    "# ==========================\n",
    "# FULL WORKING PROJECT CODE\n",
    "# ==========================\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "from xgboost import XGBRegressor\n",
    "\n",
    "# --------------------------\n",
    "# 1. DATA GENERATION\n",
    "# --------------------------\n",
    "np.random.seed(42)\n",
    "t = np.arange(1095)\n",
    "series1 = 0.05*t + 15*np.sin(2*np.pi*t/365) + np.random.normal(0,2,1095)\n",
    "series2 = 0.7*series1 + np.random.normal(0,1,1095)\n",
    "series3 = np.cumsum(np.random.normal(0,1,1095))\n",
    "\n",
    "df = pd.DataFrame({\n",
    "    'Sales_Target': series1,\n",
    "    'Foot_Traffic': series2,\n",
    "    'Market_Noise': series3\n",
    "})\n",
    "\n",
    "# --------------------------\n",
    "# 2. SCALING\n",
    "# --------------------------\n",
    "scaler = MinMaxScaler()\n",
    "data = scaler.fit_transform(df)\n",
    "\n",
    "# --------------------------\n",
    "# 3. CREATE SEQUENCES\n",
    "# --------------------------\n",
    "def create_sequences(data, seq_length=7):\n",
    "    X, y = [], []\n",
    "    for i in range(len(data)-seq_length):\n",
    "        X.append(data[i:i+seq_length])\n",
    "        y.append(data[i+seq_length,0])\n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "X, y = create_sequences(data)\n",
    "\n",
    "split = int(len(X)*0.8)\n",
    "X_train, X_test = X[:split], X[split:]\n",
    "y_train, y_test = y[:split], y[split:]\n",
    "\n",
    "X_train = torch.tensor(X_train,dtype=torch.float32)\n",
    "X_test = torch.tensor(X_test,dtype=torch.float32)\n",
    "y_train = torch.tensor(y_train,dtype=torch.float32).view(-1,1)\n",
    "y_test = torch.tensor(y_test,dtype=torch.float32).view(-1,1)\n",
    "\n",
    "# --------------------------\n",
    "# 4. LSTM MODEL\n",
    "# --------------------------\n",
    "class LSTMModel(nn.Module):\n",
    "    def __init__(self,input_dim=3,hidden_dim=64):\n",
    "        super().__init__()\n",
    "        self.lstm = nn.LSTM(input_dim,hidden_dim,batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_dim,1)\n",
    "    def forward(self,x):\n",
    "        out,_ = self.lstm(x)\n",
    "        return self.fc(out[:,-1,:])\n",
    "\n",
    "model = LSTMModel()\n",
    "optimizer = optim.Adam(model.parameters(),lr=0.001)\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "# TRAIN\n",
    "for epoch in range(50):\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    pred = model(X_train)\n",
    "    loss = criterion(pred,y_train)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    if epoch%10==0:\n",
    "        print(f\"Epoch {epoch} Loss {loss.item():.4f}\")\n",
    "\n",
    "# --------------------------\n",
    "# 5. LSTM METRICS\n",
    "# --------------------------\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    preds = model(X_test).numpy()\n",
    "    true = y_test.numpy()\n",
    "\n",
    "mae = mean_absolute_error(true,preds)\n",
    "rmse = np.sqrt(mean_squared_error(true,preds))\n",
    "mape = np.mean(np.abs((true-preds)/true))*100\n",
    "\n",
    "print(\"\\nLSTM RESULTS\")\n",
    "print(\"MAE:\",mae)\n",
    "print(\"RMSE:\",rmse)\n",
    "print(\"MAPE:\",mape)\n",
    "\n",
    "# --------------------------\n",
    "# 6. WALK FORWARD LSTM\n",
    "# --------------------------\n",
    "def walk_forward_validation(model,X,y):\n",
    "    errors=[]\n",
    "    start=int(len(X)*0.6)\n",
    "    for i in range(start,len(X)-1):\n",
    "        X_test=X[i:i+1]\n",
    "        y_true=y[i]\n",
    "        with torch.no_grad():\n",
    "            pred=model(X_test).item()\n",
    "        errors.append(abs(pred-y_true))\n",
    "    return np.mean(errors)\n",
    "\n",
    "wf_error = walk_forward_validation(model,X_test,y_test.numpy())\n",
    "print(\"Walk Forward LSTM:\",wf_error)\n",
    "\n",
    "# --------------------------\n",
    "# 7. XGBOOST\n",
    "# --------------------------\n",
    "X_xgb = X.reshape(len(X),-1)\n",
    "y_xgb = y\n",
    "\n",
    "X_train_xgb, X_test_xgb = X_xgb[:split], X_xgb[split:]\n",
    "y_train_xgb, y_test_xgb = y_xgb[:split], y_xgb[split:]\n",
    "\n",
    "xgb_model = XGBRegressor(n_estimators=200,max_depth=4,learning_rate=0.05)\n",
    "xgb_model.fit(X_train_xgb,y_train_xgb)\n",
    "\n",
    "preds_xgb = xgb_model.predict(X_test_xgb)\n",
    "\n",
    "mae_xgb = mean_absolute_error(y_test_xgb,preds_xgb)\n",
    "rmse_xgb = np.sqrt(mean_squared_error(y_test_xgb,preds_xgb))\n",
    "mape_xgb = np.mean(np.abs((y_test_xgb-preds_xgb)/y_test_xgb))*100\n",
    "\n",
    "print(\"\\nXGBOOST RESULTS\")\n",
    "print(\"MAE:\",mae_xgb)\n",
    "print(\"RMSE:\",rmse_xgb)\n",
    "print(\"MAPE:\",mape_xgb)\n",
    "\n",
    "# --------------------------\n",
    "# 8. WALK FORWARD XGB\n",
    "# --------------------------\n",
    "def walk_forward_xgb(model,X,y):\n",
    "    errors=[]\n",
    "    start=int(len(X)*0.6)\n",
    "    for i in range(start,len(X)-1):\n",
    "        pred=model.predict(X[i:i+1])[0]\n",
    "        errors.append(abs(pred-y[i]))\n",
    "    return np.mean(errors)\n",
    "\n",
    "wf_xgb = walk_forward_xgb(xgb_model,X_test_xgb,y_test_xgb)\n",
    "print(\"Walk Forward XGB:\",wf_xgb)\n",
    "\n",
    "print(\"\\nFINAL COMPARISON COMPLETE\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
