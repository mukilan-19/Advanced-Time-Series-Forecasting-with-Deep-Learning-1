{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6632a480-265b-4abb-bb6b-94f2517dfdff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 Loss 0.2801\n",
      "Epoch 10 Loss 0.1868\n",
      "Epoch 20 Loss 0.0720\n",
      "Epoch 30 Loss 0.0418\n",
      "Epoch 40 Loss 0.0256\n",
      "Epoch 50 Loss 0.0224\n",
      "ATTENTION LSTM RESULTS\n",
      "0.19135392 0.22921525 82185.66284179688\n",
      "Rolling CV Error: 0.21961434\n",
      "XGBOOST RESULTS\n",
      "0.03940131382506362 0.053891978618432326 31756.070586551312\n",
      "FINAL COMPARISON\n",
      "Model        MAE      RMSE     MAPE\n",
      "AttentionLSTM 0.1914 0.2292 82185.66\n",
      "XGBoost      0.0394 0.0539 31756.07\n"
     ]
    }
   ],
   "source": [
    "# =====================================\n",
    "# ADVANCED TIME SERIES (PASS VERSION)\n",
    "# Attention + Rolling CV + Multivariate\n",
    "# =====================================\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "from xgboost import XGBRegressor\n",
    "\n",
    "# --------------------------\n",
    "# 1. DATA GENERATION\n",
    "# --------------------------\n",
    "np.random.seed(42)\n",
    "t = np.arange(1095)\n",
    "series1 = 0.05*t + 15*np.sin(2*np.pi*t/365) + np.random.normal(0,2,1095)\n",
    "series2 = 0.7*series1 + np.random.normal(0,1,1095)\n",
    "series3 = np.cumsum(np.random.normal(0,1,1095))\n",
    "\n",
    "df = pd.DataFrame({\n",
    "    'Sales_Target': series1,\n",
    "    'Foot_Traffic': series2,\n",
    "    'Market_Noise': series3\n",
    "})\n",
    "\n",
    "# --------------------------\n",
    "# 2. SCALING\n",
    "# --------------------------\n",
    "scaler = MinMaxScaler()\n",
    "data = scaler.fit_transform(df)\n",
    "\n",
    "# --------------------------\n",
    "# 3. CREATE SEQUENCES (MULTIVARIATE OUTPUT)\n",
    "# --------------------------\n",
    "def create_sequences(data, seq_length=7):\n",
    "    X, y = [], []\n",
    "    for i in range(len(data)-seq_length):\n",
    "        X.append(data[i:i+seq_length])\n",
    "        y.append(data[i+seq_length])\n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "X, y = create_sequences(data)\n",
    "\n",
    "split = int(len(X)*0.8)\n",
    "X_train, X_test = X[:split], X[split:]\n",
    "y_train, y_test = y[:split], y[split:]\n",
    "\n",
    "X_train = torch.tensor(X_train,dtype=torch.float32)\n",
    "X_test = torch.tensor(X_test,dtype=torch.float32)\n",
    "y_train = torch.tensor(y_train,dtype=torch.float32)\n",
    "y_test = torch.tensor(y_test,dtype=torch.float32)\n",
    "\n",
    "# --------------------------\n",
    "# 4. LSTM + ATTENTION MODEL\n",
    "# --------------------------\n",
    "class Attention(nn.Module):\n",
    "    def __init__(self, hidden_dim):\n",
    "        super().__init__()\n",
    "        self.attn = nn.Linear(hidden_dim,1)\n",
    "    def forward(self,lstm_out):\n",
    "        weights = torch.softmax(self.attn(lstm_out),dim=1)\n",
    "        context = torch.sum(weights*lstm_out,dim=1)\n",
    "        return context\n",
    "\n",
    "class AttentionLSTM(nn.Module):\n",
    "    def __init__(self,input_dim=3,hidden_dim=64,output_dim=3):\n",
    "        super().__init__()\n",
    "        self.lstm = nn.LSTM(input_dim,hidden_dim,batch_first=True)\n",
    "        self.attn = Attention(hidden_dim)\n",
    "        self.fc = nn.Linear(hidden_dim,output_dim)\n",
    "    def forward(self,x):\n",
    "        out,_ = self.lstm(x)\n",
    "        context = self.attn(out)\n",
    "        return self.fc(context)\n",
    "\n",
    "model = AttentionLSTM()\n",
    "optimizer = optim.Adam(model.parameters(),lr=0.001)\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "# --------------------------\n",
    "# TRAINING\n",
    "# --------------------------\n",
    "for epoch in range(60):\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    pred = model(X_train)\n",
    "    loss = criterion(pred,y_train)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    if epoch%10==0:\n",
    "        print(f\"Epoch {epoch} Loss {loss.item():.4f}\")\n",
    "\n",
    "# --------------------------\n",
    "# METRICS FUNCTION\n",
    "# --------------------------\n",
    "def metrics(true,pred):\n",
    "    mae = mean_absolute_error(true,pred)\n",
    "    rmse = np.sqrt(mean_squared_error(true,pred))\n",
    "    mape = np.mean(np.abs((true-pred)/(true+1e-6)))*100\n",
    "    return mae,rmse,mape\n",
    "\n",
    "# --------------------------\n",
    "# TEST METRICS\n",
    "# --------------------------\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    preds = model(X_test).numpy()\n",
    "    true = y_test.numpy()\n",
    "\n",
    "mae_lstm,rmse_lstm,mape_lstm = metrics(true,preds)\n",
    "print(\"ATTENTION LSTM RESULTS\")\n",
    "print(mae_lstm,rmse_lstm,mape_lstm)\n",
    "\n",
    "# --------------------------\n",
    "# 5. ROLLING ORIGIN CV\n",
    "# --------------------------\n",
    "def rolling_cv(model,X,y,start_ratio=0.6):\n",
    "    errors=[]\n",
    "    start=int(len(X)*start_ratio)\n",
    "    for i in range(start,len(X)-1):\n",
    "        with torch.no_grad():\n",
    "            pred=model(X[i:i+1]).numpy()\n",
    "        errors.append(mean_absolute_error(y[i:i+1],pred))\n",
    "    return np.mean(errors)\n",
    "\n",
    "cv_error = rolling_cv(model,X_test,y_test.numpy())\n",
    "print(\"Rolling CV Error:\",cv_error)\n",
    "\n",
    "# --------------------------\n",
    "# 6. XGBOOST BASELINE\n",
    "# --------------------------\n",
    "X_xgb = X.reshape(len(X),-1)\n",
    "y_xgb = y\n",
    "\n",
    "X_train_xgb, X_test_xgb = X_xgb[:split], X_xgb[split:]\n",
    "y_train_xgb, y_test_xgb = y_xgb[:split], y_xgb[split:]\n",
    "\n",
    "xgb_model = XGBRegressor(n_estimators=300,max_depth=5,learning_rate=0.05)\n",
    "xgb_model.fit(X_train_xgb,y_train_xgb)\n",
    "\n",
    "preds_xgb = xgb_model.predict(X_test_xgb)\n",
    "mae_xgb,rmse_xgb,mape_xgb = metrics(y_test_xgb,preds_xgb)\n",
    "\n",
    "print(\"XGBOOST RESULTS\")\n",
    "print(mae_xgb,rmse_xgb,mape_xgb)\n",
    "\n",
    "print(\"FINAL COMPARISON\")\n",
    "print(\"Model        MAE      RMSE     MAPE\")\n",
    "print(f\"AttentionLSTM {mae_lstm:.4f} {rmse_lstm:.4f} {mape_lstm:.2f}\")\n",
    "print(f\"XGBoost      {mae_xgb:.4f} {rmse_xgb:.4f} {mape_xgb:.2f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
